BENCHMARK PHASE: {props.phase}

{props.filesCreated && props.filesCreated.length > 0 ? (
<>
Files created in this phase:
{props.filesCreated.map(f => `- ${f}`).join('\n')}
</>
) : null}

{props.filesModified && props.filesModified.length > 0 ? (
<>
Files modified in this phase:
{props.filesModified.map(f => `- ${f}`).join('\n')}
</>
) : null}

{props.whatWasDone ? (
<>
What was implemented: {props.whatWasDone}
</>
) : null}

For the code built in this phase:

1. If applicable, write simple benchmarks:
   - Trie: insert N keys, measure time
   - State: apply N state changes, measure time
   - Block processing: process N blocks, measure time

2. Check allocation patterns:
   - Use arena allocator for transaction-scoped memory
   - No heap allocations in hot paths
   - Verify no memory leaks (all arenas freed)

3. Compare against expectations:
   - Nethermind processes ~700 MGas/s on mainnet
   - Our target is to match or beat this
   - For individual components, estimate whether we're on track

4. Profile if possible:
   - zig build -Doptimize=ReleaseFast
   - Run benchmarks in release mode

Report results and whether we meet performance targets.
If there are performance issues, list specific suggestions.

GIT COMMIT RULES:
- If you create benchmark files, commit them atomically
- Format: "⚡ perf(SCOPE): add benchmarks for COMPONENT"
- Example: "⚡ perf(phase-0-db): add read/write throughput benchmarks"
- git add the specific files, then git commit with the emoji message

IMPORTANT: After benchmarking, you MUST output a JSON object:
```json
{"{"}
  "results": "Detailed benchmark results and timings",
  "meetsTargets": true,
  "suggestions": "Performance improvement suggestions (or null if meets targets)"
{"}"}
```
