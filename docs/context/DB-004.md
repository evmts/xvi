# DB-004: Add merge operation to Database vtable

## Summary

Add an optional `merge` function pointer to the Database VTable, following the same pattern as the existing `write_batch` optional field. This mirrors Nethermind's `IMergeableKeyValueStore.Merge(key, value, flags)` method. The DbSettings struct already has `merge_operator` and `columns_merge_operators` fields but nothing in the VTable calls them.

## Nethermind Architecture

### Interface Hierarchy

```
IWriteOnlyKeyValueStore
  └── IMergeableKeyValueStore (adds Merge method)

IWriteBatch : IDisposable, IWriteOnlyKeyValueStore, IMergeableKeyValueStore
  (write batches ALSO support merge)
```

### Key Files

| File | Purpose |
|------|---------|
| `nethermind/src/Nethermind/Nethermind.Core/IKeyValueStore.cs:115-118` | `IMergeableKeyValueStore` interface definition |
| `nethermind/src/Nethermind/Nethermind.Core/IWriteBatch.cs:8` | `IWriteBatch` extends `IMergeableKeyValueStore` |
| `nethermind/src/Nethermind/Nethermind.Db/IMergeOperator.cs` | `IMergeOperator` interface (FullMerge, PartialMerge) |
| `nethermind/src/Nethermind/Nethermind.Db/RocksDbSettings.cs` | `DbSettings.MergeOperator` and `ColumnsMergeOperators` fields |
| `nethermind/src/Nethermind/Nethermind.Db/RocksDbMergeEnumerator.cs` | Ref struct for merge operand enumeration |
| `nethermind/src/Nethermind/Nethermind.Db/InMemoryWriteBatch.cs:43-46` | In-memory: `throw NotSupportedException` for merge |
| `nethermind/src/Nethermind/Nethermind.Db/CompressingDb.cs:46-47` | Compressing: `throw InvalidOperationException` for merge |
| `nethermind/src/Nethermind/Nethermind.Db.Rocks/DbOnTheRocks.cs:34` | Implements `IMergeableKeyValueStore` |
| `nethermind/src/Nethermind/Nethermind.Db.Rocks/DbOnTheRocks.cs:156-169` | Initialization with merge operators |
| `nethermind/src/Nethermind/Nethermind.Db.Rocks/DbOnTheRocks.cs:489-629` | `BuildOptions` applies merge operator to RocksDB options |
| `nethermind/src/Nethermind/Nethermind.Db.Rocks/DbOnTheRocks.cs:954-986` | `Merge()` and `MergeWithColumnFamily()` implementations |
| `nethermind/src/Nethermind/Nethermind.Db.Rocks/DbOnTheRocks.cs:1338-1349` | Write batch merge support |
| `nethermind/src/Nethermind/Nethermind.Db.Rocks/MergeOperatorAdapter.cs` | Bridges C# IMergeOperator to native RocksDB callbacks |
| `nethermind/src/Nethermind/Nethermind.Db.Rocks/ColumnDb.cs:63-64` | Column DB delegates merge to main DB |
| `nethermind/src/Nethermind/Nethermind.Db/FullPruning/FullPruningDb.cs:118-122` | Full pruning duplicates merges |

### IMergeableKeyValueStore Signature

```csharp
public interface IMergeableKeyValueStore : IWriteOnlyKeyValueStore
{
    void Merge(ReadOnlySpan<byte> key, ReadOnlySpan<byte> value, WriteFlags flags = WriteFlags.None);
}
```

### IMergeOperator (for RocksDB native merge)

```csharp
public interface IMergeOperator
{
    string Name { get; }
    ArrayPoolList<byte>? FullMerge(ReadOnlySpan<byte> key, RocksDbMergeEnumerator enumerator);
    ArrayPoolList<byte>? PartialMerge(ReadOnlySpan<byte> key, RocksDbMergeEnumerator enumerator);
}
```

### Key Behavioral Notes

1. **Merge is RocksDB-specific**: In-memory and compressing backends throw `NotSupportedException`
2. **Write batches include merge**: `IWriteBatch` extends `IMergeableKeyValueStore`, so batches must also support merge (or throw)
3. **Column family support**: `MergeWithColumnFamily()` takes an extra `ColumnFamilyHandle` parameter
4. **GC safety**: Merge operators stored in `_doNotGcOptions` to prevent GC during native callbacks
5. **Merge vs Put**: Merge uses RocksDB's native merge operator for efficient read-modify-write without read-before-write

## Existing Zig Implementation

### Current VTable (adapter.zig)

The `write_batch` optional field pattern (lines 417-429):

```zig
pub const VTable = struct {
    // ... required fields ...
    write_batch: ?*const fn (ptr: *anyopaque, ops: []const WriteBatchOp) Error!void = null,
};
```

### DbSettings (rocksdb.zig:42-80)

Already has merge operator fields:

```zig
pub const DbSettings = struct {
    name: DbName,
    path: []const u8,
    delete_on_start: bool = false,
    can_delete_folder: bool = true,
    merge_operator: ?*const anyopaque = null,
    columns_merge_operators: ?*const std.StringHashMapUnmanaged(*const anyopaque) = null,
    // ...
};
```

### Database.init Comptime Helper (adapter.zig:541-637)

Shows how optional vtable entries are wired:

```zig
pub fn init(comptime T: type, ptr: *T, comptime fns: struct {
    // ... required functions ...
    write_batch: ?*const fn (self: *T, ops: []const WriteBatchOp) Error!void = null,
}) Database {
    const Wrapper = struct {
        // ...
        const vtable = VTable{
            // ...
            .write_batch = if (fns.write_batch == null) null else write_batch_impl,
        };
    };
    // ...
}
```

### Convenience Methods on Database (adapter.zig:504-513)

```zig
pub fn supports_write_batch(self: Database) bool {
    return self.vtable.write_batch != null;
}

pub fn start_write_batch(self: Database, allocator: std.mem.Allocator) WriteBatch {
    return WriteBatch.init(allocator, self);
}
```

### WriteBatchOp (adapter.zig:682-695)

Currently only supports `put` and `del`:

```zig
pub const WriteBatchOp = union(enum) {
    put: struct { key: []const u8, value: []const u8 },
    del: struct { key: []const u8 },
};
```

### WriteFlags (adapter.zig:137-155)

Already defined, matches Nethermind:

```zig
pub const WriteFlags = struct {
    bits: u8,
    pub const none = WriteFlags{ .bits = 0 };
    pub const low_priority = WriteFlags{ .bits = 1 };
    pub const disable_wal = WriteFlags{ .bits = 2 };
    pub const low_priority_and_no_wal = WriteFlags{ .bits = low_priority.bits | disable_wal.bits };
    // ...
};
```

### Existing Tests for write_batch Pattern (adapter.zig)

| Test Name | Line | Purpose |
|-----------|------|---------|
| `"Database supports_write_batch reports false when absent"` | 939 | Verifies null optional |
| `"Database supports_write_batch reports true when present"` | 946 | Verifies non-null optional |
| `"WriteBatch: uses write_batch vtable for atomic commit"` | ~1524 | Atomic path works |
| `"WriteBatch: sequential fallback retains ops on error for retry"` | ~1580 | Fallback path works |

### Backend Files That Need Updating

| File | Current State | Needed |
|------|--------------|--------|
| `client/db/adapter.zig` | No merge in VTable | Add optional `merge` fn ptr, `supports_merge()`, `merge()` method |
| `client/db/adapter.zig` | WriteBatchOp has put/del | Add `merge` variant to WriteBatchOp |
| `client/db/adapter.zig` | WriteBatch.commit handles put/del | Handle merge ops in both atomic and fallback paths |
| `client/db/adapter.zig` | Database.init has write_batch optional | Add `merge` optional in comptime init helper |
| `client/db/memory.zig` | No merge support | No change needed (null = unsupported) |
| `client/db/null.zig` | No merge support | No change needed (null = unsupported) |
| `client/db/rocksdb.zig` | DbSettings has merge_operator | Will use this when RocksDB FFI is implemented |
| `client/db/columns.zig` | ColumnsWriteBatch | May need merge variant forwarding |
| `client/db/read_only.zig` | ReadOnlyDb | May need merge passthrough |

## Voltaire APIs

Voltaire does NOT provide database-level primitives. The DB adapter layer is intentionally below Voltaire's state management. No Voltaire types needed for this ticket.

Relevant Voltaire types (for future context):
- `voltaire/packages/voltaire-zig/src/state-manager/` — State manager that will sit above this DB layer
- No `KeyValueStore`, `Database`, or merge-related types exist in Voltaire

## Spec References

No Ethereum execution specs are directly relevant — this is an internal database abstraction. However, merge operators will be used for:
- Efficient state trie updates (avoiding read-before-write for account nonce/balance increments)
- Verkle trie implementations (mentioned in ticket description)
- Log accumulation patterns

## Implementation Plan

### Step 1: Add `merge` to VTable

```zig
// In VTable struct, after write_batch:
merge: ?*const fn (ptr: *anyopaque, key: []const u8, value: []const u8, flags: WriteFlags) Error!void = null,
```

### Step 2: Add convenience methods to Database

```zig
pub fn supports_merge(self: Database) bool {
    return self.vtable.merge != null;
}

pub fn merge(self: Database, key: []const u8, value: []const u8) Error!void {
    return self.merge_with_flags(key, value, .none);
}

pub fn merge_with_flags(self: Database, key: []const u8, value: []const u8, flags: WriteFlags) Error!void {
    const merge_fn = self.vtable.merge orelse return error.StorageError;
    return merge_fn(self.ptr, key, value, flags);
}
```

### Step 3: Add `merge` to WriteBatchOp

```zig
pub const WriteBatchOp = union(enum) {
    put: struct { key: []const u8, value: []const u8 },
    del: struct { key: []const u8 },
    merge: struct { key: []const u8, value: []const u8 },
};
```

### Step 4: Add merge to WriteBatch

```zig
pub fn merge(self: *WriteBatch, key: []const u8, value: []const u8) Error!void {
    const alloc = self.arena.allocator();
    const owned_key = alloc.dupe(u8, key) catch return error.OutOfMemory;
    const owned_val = alloc.dupe(u8, value) catch return error.OutOfMemory;
    self.ops.append(self.ops_allocator, .{ .merge = .{ .key = owned_key, .value = owned_val } }) catch return error.OutOfMemory;
}
```

### Step 5: Update WriteBatch.commit fallback path

```zig
for (self.ops.items) |op| {
    switch (op) {
        .put => |p| try self.target.put(p.key, p.value),
        .del => |d| try self.target.delete(d.key),
        .merge => |m| try self.target.merge_with_flags(m.key, m.value, .none),
    }
}
```

### Step 6: Update Database.init comptime helper

Add `merge` optional parameter alongside `write_batch`.

### Step 7: Add tests

- `"Database supports_merge reports false when absent"`
- `"Database supports_merge reports true when present"`
- `"Database merge returns error when unsupported"`
- `"Database merge delegates to vtable"`
- `"WriteBatch merge accumulates operations"`
- `"WriteBatch commit applies merge ops in fallback path"`
- `"WriteBatchOp merge variant holds key and value"`

## Test Fixtures

No external test fixtures — unit tests only (Phase 0 is internal abstraction).

## Risk Assessment

- **Low risk**: This is additive only — no existing behavior changes
- **Backward compatible**: All existing backends continue to work with `merge: null`
- **Pattern established**: Follows exact same pattern as `write_batch` optional
- **Future use**: Will be consumed by RocksDB FFI backend and trie implementations
